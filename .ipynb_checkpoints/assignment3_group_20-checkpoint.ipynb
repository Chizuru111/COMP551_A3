{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install numpy\n",
        "%pip install pandas\n",
        "%pip install matplotlib"
      ],
      "metadata": {
        "id": "atf6xqy8vcKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu_5hJNc5-wX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from IPython.core.debugger import set_trace\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from typing import List\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "3hRNsvGht1F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for dirname, _, filenames in os.walk(('/kaggle/input')):\n",
        "#   for filename in filenames:\n",
        "#     print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "VGzUdHG46vwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Preprocessing the dataset"
      ],
      "metadata": {
        "id": "QBWyCCghKUwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('/Programming/COMP551/COMP551_A3/dataset/sign_mnist_train.csv')\n",
        "train_df=pd.read_csv('/Programming/COMP551/COMP551_A3/dataset/sign_mnist_test.csv')"
      ],
      "metadata": {
        "id": "8iwkVzNhKkhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "j41KLHiYNKYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "WOvoUakdNT9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.info()"
      ],
      "metadata": {
        "id": "jiSdvx0eNvv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train_df dataset consit of 1st column representing labels 1 to 24. The label is loaded in a separate dataframe called 'train_label' and the 'label' column is dropped from the original training dataframe which now consist of only 784 pixel values for each image."
      ],
      "metadata": {
        "id": "qI78tJABN4Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the label column for the train_df\n",
        "train_label = train_df['label']\n",
        "trainset = train_df.drop(['label'], axis=1)\n",
        "# Convert the dataframe to numpy array\n",
        "X_train = trainset.values.astype(np.float64)\n",
        "\n",
        "# Same thing for the test_df\n",
        "test_label = test_df['label']\n",
        "testset = test_df.drop(['label'], axis=1)\n",
        "# Convert the dataframe to numpy array\n",
        "X_test = testset.values.astype(np.float64)"
      ],
      "metadata": {
        "id": "rY3WNnVDOVcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encodding"
      ],
      "metadata": {
        "id": "LfpFkDs0RpRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_test = lb.fit_transform(test_label)"
      ],
      "metadata": {
        "id": "7AgJuz_GQU6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizatioin and Vectorization"
      ],
      "metadata": {
        "id": "K25seuBhSZpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mean = np.mean(X_train)\n",
        "X_train_std = np.std(X_train, axis=0)\n",
        "# For images, subtract a single data from all pixels\n",
        "X_train -= X_train_mean\n",
        "X_train /= X_train_std + 1e-5\n",
        "\n",
        "X_test -= X_train_mean\n",
        "X_test /= X_train_std + 1e-5\n",
        "\n",
        "# Vectorization\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "sJGqaUkTTpKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 hidden layers MLP"
      ],
      "metadata": {
        "id": "1dvcmZuzWfCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetlayer:\n",
        "  def __init_(self):\n",
        "    self.gradient = None\n",
        "    self.parameters = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def backward(self, gradient):\n",
        "    raise NotImplementedError"
      ],
      "metadata": {
        "id": "QD2SN3m4Wq0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearLayer(NeuralNetlayer):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.ni = input_size\n",
        "    self.no = output_size\n",
        "    self.w = np.random.randn(output_size, input_size)\n",
        "    self.b = np.random.randn(output_size)\n",
        "    self.cur_input = None\n",
        "    self.parameters = [self.w, self.b]\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.cur_input = x\n",
        "    return (self.w[None, :, :] @ x[:, :, None]).squeeze() + self.b\n",
        "\n",
        "  def backward(self, gradient):\n",
        "    assert self.cur_input is not None, \"Must call forward before backward!\"\n",
        "    # dw = gradient.dot(self.cur_input)\n",
        "    dw = gradient[:, :, None] @ self.cur_input[:, None, :]\n",
        "    db = gradient\n",
        "    self.gradient = [dw, db]\n",
        "    return gradient.dot(self.w)"
      ],
      "metadata": {
        "id": "_SKkpiaXXmYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLULayer(NeuralNetLayer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.gradient = np.where(x > 0, 1.0, 0.0)\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, gradient):\n",
        "        assert self.gradient is not None, \"Must call forward before backward\"\n",
        "        return gradient * self.gradient"
      ],
      "metadata": {
        "id": "Kv_AP7VvScrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxOutputLayer(NeuralNetLayer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cur_probs = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        exps = np.exp(x)\n",
        "        probs = exps / np.sum(exps, axis=-1)[:, None]\n",
        "        self.cur_probs = probs\n",
        "        return probs\n",
        "\n",
        "    def backward(self, target):\n",
        "        assert self.cur_probs is not None, \"Must call forward before backward\"\n",
        "        return self.cur_probs - target"
      ],
      "metadata": {
        "id": "gsBVKwhIqPPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, *args: List[NeuralNetLayer]):\n",
        "        self.layers = args\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, target):\n",
        "        for layer in self.layers[::-1]:\n",
        "            target = layer.backward(target)"
      ],
      "metadata": {
        "id": "XVngHzZtqU7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer:\n",
        "    def __init__(self, net: MLP):\n",
        "        self.net = net\n",
        "\n",
        "    def step(self):\n",
        "        for layer in self.net.layers[::-1]:\n",
        "            if layer.parameters is not None:\n",
        "                self.update(layer.parameters, layer.gradient)\n",
        "\n",
        "    def update(self, params, gradient):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class GradientDescentOptimizer(Optimizer):\n",
        "    def __init__(self, net: MLP, lr: float):\n",
        "        super().__init__(net)\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, params, gradient):\n",
        "        for (p, g) in zip(params, gradient):\n",
        "            p -= self.lr * g.mean(axis=0)"
      ],
      "metadata": {
        "id": "JWtqWoJqsC5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(mlp: MLP, optimizer: Optimizer, data_x, data_y, steps):\n",
        "    losses = []\n",
        "    labels = np.eye(3)[np.array(data_y)]\n",
        "    for _ in tqdm(range(steps)):\n",
        "        predictions = mlp.forward(data_x)\n",
        "        loss = -(labels * np.log(predictions)).sum(axis=-1).mean()\n",
        "        losses.append(loss)\n",
        "        mlp.backward(labels)\n",
        "        optimizer.step()\n",
        "    plt.plot(losses)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Cross entropy loss\")"
      ],
      "metadata": {
        "id": "JIulsf4_sKYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X_train.shape[0]\n",
        "HIDDEN_SIZE = 64\n",
        "GRADIENT_STEPS = 200\n",
        "\n",
        "mlp2 = MLP(\n",
        "    LinearLayer(n_features, HIDDEN_SIZE),\n",
        "    ReLULayer(),\n",
        "    LinearLayer(HIDDEN_SIZE, HIDDEN_SIZE),\n",
        "    ReLULayer(),\n",
        "    LinearLayer(HIDDEN_SIZE, 3),\n",
        "    SoftmaxOutputLayer()\n",
        ")\n",
        "opt2 = GradientDescentOptimizer(mlp2, 1e-2)\n",
        "\n",
        "train(mlp2, opt2, X_train, y_train, GRADIENT_STEPS)"
      ],
      "metadata": {
        "id": "dCxRLqgusQlE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}